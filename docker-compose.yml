services:
  app:
    build: .
    image: ml-project:latest
    working_dir: /app
    volumes:
      - ./src:/app/src
      - ./configs:/app/configs
      - ./scripts:/app/scripts
      - ./artifacts:/app/artifacts
      - ./outputs:/app/outputs
    environment:
      - PYTHONUNBUFFERED=1
    entrypoint: ["/app/entrypoint.sh"]
    # Usage: docker-compose run app train
    #        docker-compose run app inference

  mlflow:
    image: ghcr.io/mlflow/mlflow:latest
    ports:
      - "5000:5000"
    volumes:
      - ./artifacts:/mlflow/artifacts
    environment:
      - MLFLOW_TRACKING_URI=http://0.0.0.0:5000
    command: >
      mlflow server
      --backend-store-uri sqlite:////mlflow/mlflow.db
      --default-artifact-root /mlflow/artifacts
      --host 0.0.0.0
    # Optional: set mlflow.enabled: true in configs/config.yaml if using
